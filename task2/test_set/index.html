<!DOCTYPE HTML>
<html lang="en">
    <head>

<title>Test Set Task 2 | ICASSP 2024: Auditory EEG challenge</title>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
<link rel="stylesheet" href="/auditory-eeg-challenge-2024/style.css" />
<meta property="og:title" content="Test Set Task 2" />
<meta property="og:description" content="description of the test set for task 2" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://exporl.github.io/auditory-eeg-challenge-2024/task2/test_set/" /><meta property="article:section" content="task2" />



</head>
    <body class="is-preload">
        <div id="page-wrapper"><div id="header">
    <h1><a href="https://exporl.github.io/auditory-eeg-challenge-2024/" id="logo">
        Auditory EEG Challenge - ICASSP 2024
    </a></h1>

    <nav id="nav">
        <ul>
                <li class="">
                    <a href="/auditory-eeg-challenge-2024/">Home</a>
                <li class="">
                    <a href="/auditory-eeg-challenge-2024/dataset/">Dataset</a>
                <li class="">
                    <a href="/auditory-eeg-challenge-2024/registration/">Registration</a>
                <li class="">
                    <a href="#">Task 1: Match-Mismatch</a><ul>
                        <li class="">
                            <a href="/auditory-eeg-challenge-2024/task1/description">description</a>
                        <li class="">
                            <a href="/auditory-eeg-challenge-2024/task1/test_set">test_set</a>
                        <li class="">
                            <a href="/auditory-eeg-challenge-2024/task1/leaderboard">leaderboard</a>
                    </ul>
                <li class="">
                    <a href="#">Task 2: Regression</a><ul>
                        <li class="">
                            <a href="/auditory-eeg-challenge-2024/task2/description">description</a>
                        <li class="">
                            <a href="/auditory-eeg-challenge-2024/task2/test_set">test_set</a>
                        <li class="">
                            <a href="/auditory-eeg-challenge-2024/task2/leaderboard">leaderboard</a>
                    </ul>
        </ul>
    </nav>
</div>

            <section class="wrapper style1">
                <div class="container">
                    

                        <div class="">
                            <div id="content">
                                <article>
    <header>
        <h2>Test Set Task 2</h2>
        <p>description of the test set for task 2</p>
        
        
        <ul class="tags">
</ul>

    </header><hr>
<h3 id="provided-test-dataset">Provided test dataset</h3>
<p>The test data for this task can be downloaded from <a href="https://homes.esat.kuleuven.be/~lbollens/sparrkulee/test_set">here</a>.
The password is the same one as provided for the training set.
The directory contains following items:</p>
<ol>
<li>
<p><strong>sub-x_mapping.json</strong>: These files link the EEG files to the possible stimuli.
Since you are free to use whatever version of the data you want, these json files contain
keys to the EEG files. Each entry in the json file is of the form:
<strong>(segment_ID) : {&rsquo;eeg&rsquo;: eeg_id}</strong>.</p>
</li>
<li>
<p><strong>EEG data</strong>: the EEG data is provided in three formats: preprocessed, raw and half-preprocessed.
Each directory contains 20 subjects&rsquo; test data in the format
of sub-*.npz. Each  file contains a python dictionary with entries of the form:
<strong>eeg_id : EEG_data</strong>. We provide the following three formats:</p>
<ul>
<li>
<p><strong>preprocessed_eeg/sub-*.npz : Preprocessed EEG test samples</strong>:
If you used the already preprocessed data for training your models, this is the test data you want to use.
The same preprocessing steps were applied to this data as to the training data and you can directly use it for testing.
Each EEG segment is 5 seconds long, sampled at 64 Hz and it contains 64 channels.</p>
</li>
<li>
<p><strong>raw_eeg/sub-*.npz : Raw EEG test samples</strong>:
If you prefer to preprocess the EEG data yourself, you can use this directory. The EEG entries in this directory
are synchronized to the stimulus data, but other than that, no preprocessing was applied. All EEG entries are 5 seconds long,
sampled at 1024~Hz. If you are interested in using these data, you can take a look at the <a href="https://github.com/exporl/auditory-eeg-challenge-2024-code/blob/main/preprocessing_code/sparKULee_loadRAWtestfiles.py">sparKULee_loadRAWtestfiles.py</a> file.
This file loads in the raw EEG data and applies our preprocessing steps to it, in order to arrive at the preprocessed EEG data.</p>
</li>
<li>
<p><strong>MWFilter_eeg/sub-*.npz : Half-preprocessed EEG test samples</strong>:
If you want to preprocess the EEG data yourself, but you want to use some of the same preprocessing steps as we did, you can use this directory.
If you are interested in using these data, you can take a look at the <a href="https://github.com/exporl/auditory-eeg-challenge-2024-code/blob/main/preprocessing_code/sparKULee_loadmwffiles.py">sparKULee_loadmwffiles.py</a> file.
In more detail, this is data on which some of the preprocessing steps of our pipeline have been applied:</p>
<ul>
<li>aligment with stimulus</li>
<li>highpass-filtering (SosFiltFilt)</li>
<li>Artifact interpolation</li>
<li>Artifact removal (MWFilter)</li>
</ul>
<p>Thus, the data is stored at 1024 Hz, but the data is not yet downsampled to 64 Hz.
We opted to include these data, since some of the preprocessing steps, namely the artifact removal using a MWF filter, use an average over time to remove the artifacts.
When using segments of just 5 seconds, these steps are not as effective as when using longer segments and might produce different results. For the 30 seconds windows of the regression task, we hypothesize that this pose less of a problem, however, you are still free to use these files.<br>
If you have any more questions about these data, please contact us.</p>
</li>
</ul>
</li>
</ol>
<p>If you have any more questions about these data, or about the usage of raw data, please contact us.</p>
<h3 id="usage-example">Usage example</h3>
<p>If you use the preprocessed version of the EEG data
you can use <a href="https://github.com/exporl/auditory-eeg-challenge-2024-code/blob/main/task2_regression/experiments/test_regression.py">the provided code</a> to load in the data and use it for testing.
This code will load in a baseline pretrained model,
loop over all the data of the test set, predict the output labels and return json files in the correct format.</p>
<h3 id="expected-output">Expected output</h3>
<p>As an output, participants should upload a zip file, containing json files to <a href="https://kuleuven-my.sharepoint.com/:f:/g/personal/lies_bollens_kuleuven_be/EhTPDzpHeg1LoLxmRNNt968BLSEFSJ8F6TecZepRHhdjMg">the following link</a>
The files should follow the following naming convention:</p>
<p>task_2_group_<strong>group_name</strong>_submission _<strong>submission_number</strong>.zip</p>
<p>where <strong>submission_number</strong> should be 1 for
the first submission and can go up to 2. We will use the latest submission as the final submission, from which the ranking will be calculated. Groups that have not yet supplied their group name, should send a mail to the
organisers where they specify their name. When uploading, you will be prompted to enter a name. Please enter the name of one of the officially registered participants.</p>
<p>The json file(s) should contain the predicted labels for all ID segments, which can be found in the mapping ( in the form of <strong>(segment_ID) : {&rsquo;eeg&rsquo;: eeg_id}</strong>.)
Each entry in the submitted file should be of the form <strong>segment_ID : label</strong>.</p>
<p>The json file(s) should contain the predicted labels for all EEG segments.
Each entry in the submitted dictionary should be of the form (EEG ID) : (Reconstructed Mel).</p>
<p>A correlation value of 0 will be taken in case of absent EEG ID entries.
The reconstructed mel should be of dimensions 10 x 1920 (i.e., 30 seconds of data at the prescribed sample rate of 64 Hz).</p>
<p>For evaluation, we will calculate the mean correlation score over bands, per subject. Then, we will calculate the mean over all the subjects means to obtain a final <strong>score</strong>, which will be updated in the online leaderboard.</p>


                                </article>
                            </div>
                        </div>

                    
                </div>
            </section><div id="footer">
    <div class="container">
        <div class="row">
        </div>
    </div>

    <ul class="icons">
    </ul>

    <div class="copyright">
        <ul class="menu">
            
                <li>Design: <a href="https://html5up.net">HTML5 UP</a>
                <li><a href="https://github.com/half-duplex/hugo-arcana">Theme</a>
        </ul>
    </div>
</div>
</div><script src="/auditory-eeg-challenge-2024/js/jquery.min.js"></script>
<script src="/auditory-eeg-challenge-2024/js/jquery.dropotron.min.js"></script>
<script src="/auditory-eeg-challenge-2024/js/browser.min.js"></script>
<script src="/auditory-eeg-challenge-2024/js/breakpoints.min.js"></script>
<script src="/auditory-eeg-challenge-2024/js/util.js"></script>
<script src="/auditory-eeg-challenge-2024/js/main.js"></script>
</body>
</html>
