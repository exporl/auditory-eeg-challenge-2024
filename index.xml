<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Home on ICASSP 2024: Auditory EEG challenge</title>
    <link>https://exporl.github.io/auditory-eeg-challenge-2024/</link>
    <description>Recent content in Home on ICASSP 2024: Auditory EEG challenge</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language><atom:link href="https://exporl.github.io/auditory-eeg-challenge-2024/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>General description</title>
      <link>https://exporl.github.io/auditory-eeg-challenge-2024/homepage_sections/general_description/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://exporl.github.io/auditory-eeg-challenge-2024/homepage_sections/general_description/</guid>
      <description>Test set update The test set is now online. Downloading the test set: link. There is a separate folder for each task. For more information, look at the specific descriptions, for either Task 1 or Task 2.
Challenge Call Various neuroimaging techniques can be used to investigate how the brain processes sound. Electroencephalography (EEG) is popular because it is relatively easy to conduct and has a high temporal resolution. Besides fundamental neuroscience research, EEG-based measures of auditory processing in the brain are also helpful in detecting or diagnosing potential hearing loss.</description>
    </item>
    
    <item>
      <title>Get started</title>
      <link>https://exporl.github.io/auditory-eeg-challenge-2024/homepage_sections/leaderboard/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://exporl.github.io/auditory-eeg-challenge-2024/homepage_sections/leaderboard/</guid>
      <description>Get started Send a mail to auditoryeegchallenge@kuleuven.be with the names of the team members, emails, and affiliations. You will receive a password to download the data Download the data from ICASSP-2023-eeg-decoding-challenge-dataset split_data(.zip) contains already preprocessed, split and normalized data; ready for model training/evaluation. If you want to get started quickly, you can opt to only download this folder/zipfile. preprocessed_eeg(.zip) and preprocessed_stimuli(.zip) contain preprocessed EEG and stimuli files ( speech envelope and mel spectrogram features) respectively.</description>
    </item>
    
    <item>
      <title>Timeline</title>
      <link>https://exporl.github.io/auditory-eeg-challenge-2024/homepage_sections/timeline/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://exporl.github.io/auditory-eeg-challenge-2024/homepage_sections/timeline/</guid>
      <description> August 30,2023 Registration opens August 30, 2023: Release of training set, code, baseline methods and documentation November 15, 2023 November 28, 2023: Release of evaluation test set December 22, 2023 December 26, 2023: Deadline for submitting results for both tasks January 2, 2024: ICASSP 2024 grand challenge 2-page paper deadline (top 5 teams only) January 16, 2024: ICASSP 2024 grand challenge 2-page paper acceptance notification January 23, 2024: ICASSP 2024 grand challenge 2-page camera-ready deadline April 14-19, 2024: ICASSP 2024 conference June 19 2024: IEEE open journal of signal processing grand challenge papers deadline </description>
    </item>
    
    <item>
      <title>Dataset</title>
      <link>https://exporl.github.io/auditory-eeg-challenge-2024/dataset/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://exporl.github.io/auditory-eeg-challenge-2024/dataset/</guid>
      <description>The training set can be downloaded here, using the password which will be provided to all registered teams: ICASSP-2024-eeg-decoding-challenge-dataset
For more details concerning the dataset, we refer to our dataset paper.
EEG Electroencephalography (EEG) is a non-invasive method to record electrical activity in the brain, which is generated by ionic currents that flow within and across neuron cells. When a large population of thousands or millions of neurons with a similar orientation in a specific brain region synchronises its electrical activity, the produced electrical field is large enough to be observable on the scalp.</description>
    </item>
    
    <item>
      <title>leaderboard</title>
      <link>https://exporl.github.io/auditory-eeg-challenge-2024/task1/leaderboard/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://exporl.github.io/auditory-eeg-challenge-2024/task1/leaderboard/</guid>
      <description> All results Group nameSubmission number Within subjects mean Within subjects std Heldout subjects mean Heldout subjects std total score </description>
    </item>
    
    <item>
      <title>leaderboard</title>
      <link>https://exporl.github.io/auditory-eeg-challenge-2024/task2/leaderboard/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://exporl.github.io/auditory-eeg-challenge-2024/task2/leaderboard/</guid>
      <description> All results Group nameSubmission number Within subjects mean Within subjects std Heldout subjects mean Heldout subjects std total score </description>
    </item>
    
    <item>
      <title>Organizers</title>
      <link>https://exporl.github.io/auditory-eeg-challenge-2024/homepage_sections/organizers/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://exporl.github.io/auditory-eeg-challenge-2024/homepage_sections/organizers/</guid>
      <description>Organizers Lies Bollens 1, 2 (lies.bollens@esat.kuleuven.be)
Corentin Puffay 1, 2 (corentin.puffay@kuleuven.be)
Bernd Accou 1, 2
Hugo Van hamme 1
Tom Francart 2
KU Leuven, PSI, Dept. of Electrical engineering (ESAT), Leuven, Belgium
KU Leuven, ExpORL, Dept. Neurosciences, Leuven, Belgium</description>
    </item>
    
    <item>
      <title>Registration</title>
      <link>https://exporl.github.io/auditory-eeg-challenge-2024/registration/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://exporl.github.io/auditory-eeg-challenge-2024/registration/</guid>
      <description>Registration Teams can register by sending a mail to auditoryeegchallenge@kuleuven.be with the names of the team members, emails, and affiliations. Upon confirmation, teams will receive access to the training data.
Guidelines for participants Participants can submit their predictions up to two times. The latest received submission counts as the official score. The Audio-EEG challenge features two separate tasks. Participants can submit to either one track or both. Results should be accom- panied by a 2-page paper describing the proposed method The top 5 ranked teams will be invited to submit a 2-page paper, to be presented at ICASSP-2024, which should be submitted before the camera-ready deadline.</description>
    </item>
    
    <item>
      <title>Task 1: Match-mismatch</title>
      <link>https://exporl.github.io/auditory-eeg-challenge-2024/task1/description/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://exporl.github.io/auditory-eeg-challenge-2024/task1/description/</guid>
      <description>Schematic overview of the match-mismatch task Description Task 1 is a classification problem in a match-mismatch paradigm. Last year (ICASSP 2023 edition), the challenge was to select the matched stimulus segment among two candidates. This year, we modify the paradigm to make it more challenging, by presenting five candidates to the model.
The complete input to the model is structured as follows:
a segment of EEG, the time-aligned speech stimulus (matched segment) four imposter stimuli (mismatched segments) The task of the model is to determine which of the input stimulus segments corresponds to the EEG.</description>
    </item>
    
    <item>
      <title>Task 2: Regression</title>
      <link>https://exporl.github.io/auditory-eeg-challenge-2024/task2/description/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://exporl.github.io/auditory-eeg-challenge-2024/task2/description/</guid>
      <description>Schematic overview of the regression task Description Task 2 is a regression problem: To reconstruct the mel spectrogram from the EEG. Compared to the challenge from last year, this objective is slightly more difficult, as it contains more speech information than the envelope. We define a mel spectorgram with 10 subbands, distributed between 0 and 5000 Hz, calculated by the librosa library ( see preprocessing_code/mel.py). After reconstruction, a metric to measure the similarity is used between the reconstructed mel and the original mel.</description>
    </item>
    
    <item>
      <title>Test Set Task 1</title>
      <link>https://exporl.github.io/auditory-eeg-challenge-2024/task1/test_set/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://exporl.github.io/auditory-eeg-challenge-2024/task1/test_set/</guid>
      <description>Provided test dataset The test data for this task can be downloaded from here. The password is the same one as provided for the training set. The directory contains following items:
sub-x_mapping.json: These files link the EEG files to the possible stimuli. Since you are free to use whatever version of the data you want, these json files contain keys to the EEG files and the corresponding stimuli. Each entry in the json file is of the form: (segment_ID) : {&amp;rsquo;eeg&amp;rsquo;: eeg_id, &amp;lsquo;stimulus&amp;rsquo;: (stimulus_0_id, stimulus_1_id, stimulus_2_id, stimulus_3_id, stimulus_4_id)}.</description>
    </item>
    
    <item>
      <title>Test Set Task 2</title>
      <link>https://exporl.github.io/auditory-eeg-challenge-2024/task2/test_set/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://exporl.github.io/auditory-eeg-challenge-2024/task2/test_set/</guid>
      <description>Provided test dataset The test data for this task can be downloaded from here. The password is the same one as provided for the training set. The directory contains following items:
sub-x_mapping.json: These files link the EEG files to the possible stimuli. Since you are free to use whatever version of the data you want, these json files contain keys to the EEG files. Each entry in the json file is of the form: (segment_ID) : {&amp;rsquo;eeg&amp;rsquo;: eeg_id}.</description>
    </item>
    
  </channel>
</rss>
