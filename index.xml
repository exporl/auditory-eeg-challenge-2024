<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Home on ICASSP 2024: Auditory EEG challenge</title>
    <link>https://exporl.github.io/auditory-eeg-challenge-2024/</link>
    <description>Recent content in Home on ICASSP 2024: Auditory EEG challenge</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language><atom:link href="https://exporl.github.io/auditory-eeg-challenge-2024/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>General description</title>
      <link>https://exporl.github.io/auditory-eeg-challenge-2024/homepage_sections/general_description/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://exporl.github.io/auditory-eeg-challenge-2024/homepage_sections/general_description/</guid>
      <description>Challenge Call Various neuroimaging techniques can be used to investigate how the brain processes sound. Electroencephalography (EEG) is popular because it is relatively easy to conduct and has a high temporal resolution. Besides fundamental neuroscience research, EEG-based measures of auditory processing in the brain are also helpful in detecting or diagnosing potential hearing loss. They enable differential diagnosis of populations that can otherwise not be tested, such as young children or people with mental disabilities.</description>
    </item>
    
    <item>
      <title>Get started</title>
      <link>https://exporl.github.io/auditory-eeg-challenge-2024/homepage_sections/leaderboard/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://exporl.github.io/auditory-eeg-challenge-2024/homepage_sections/leaderboard/</guid>
      <description>Get started Send a mail to auditoryeegchallenge@kuleuven.be with the names of the team members, emails, and affiliations. You will receive a password to download the data Download the data from [https://rdr.kuleuven.be/dataset.xhtml?persistentId=doi:10.48804/K3VSND](our official repository) or get the already zipped files from ICASSP-2023-eeg-decoding-challenge-dataset split_data(.zip) contains already preprocessed, split and normalized data; ready for model training/evaluation. If you want to get started quickly, you can opt to only download this folder/zipfile. preprocessed_eeg(.zip) and preprocessed_stimuli(.</description>
    </item>
    
    <item>
      <title>Timeline</title>
      <link>https://exporl.github.io/auditory-eeg-challenge-2024/homepage_sections/timeline/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://exporl.github.io/auditory-eeg-challenge-2024/homepage_sections/timeline/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Dataset</title>
      <link>https://exporl.github.io/auditory-eeg-challenge-2024/dataset/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://exporl.github.io/auditory-eeg-challenge-2024/dataset/</guid>
      <description>The training set can be downloaded here, using the password which will be provided to all registered teams: ICASSP-2023-eeg-decoding-challenge-dataset
For more details concerning the dataset, we refer to the dataset paper.
EEG Electroencephalography (EEG) is a non-invasive method to record electrical activity in the brain, which is generated by ionic currents that flow within and across neuron cells. When a large population of thousands or millions of neurons with a similar orientation in a specific brain region synchronises its electrical activity, the produced electrical field is large enough to be observable on the scalp.</description>
    </item>
    
    <item>
      <title>leaderboard</title>
      <link>https://exporl.github.io/auditory-eeg-challenge-2024/task1/leaderboard/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://exporl.github.io/auditory-eeg-challenge-2024/task1/leaderboard/</guid>
      <description> All results Group nameSubmission number Within subjects mean Within subjects std Heldout subjects mean Heldout subjects std total score Challenge winners (top 3 teams):
UnderDawgs (82.13 %) HyperAttention (79.05 %) MINWPU (78.94 %) </description>
    </item>
    
    <item>
      <title>leaderboard</title>
      <link>https://exporl.github.io/auditory-eeg-challenge-2024/task2/leaderboard/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://exporl.github.io/auditory-eeg-challenge-2024/task2/leaderboard/</guid>
      <description> All results Group nameSubmission number Within subjects mean Within subjects std Heldout subjects mean Heldout subjects std total score Challenge winners (top 2 teams):
HappyQuoka (0.1589) TheBrainwaveBandits (0.1535) </description>
    </item>
    
    <item>
      <title>Organizers</title>
      <link>https://exporl.github.io/auditory-eeg-challenge-2024/homepage_sections/organizers/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://exporl.github.io/auditory-eeg-challenge-2024/homepage_sections/organizers/</guid>
      <description>Organizers Mohammad Jalilpour Monesi 1, 2 (mohammad.jalilpourmonesi@esat.kuleuven.be)
Lies Bollens 1, 2 (lies.bollens@esat.kuleuven.be)
Bernd Accou 1, 2
Hugo Van hamme 1
Tom Francart 2
KU Leuven, PSI, Dept. of Electrical engineering (ESAT), Leuven, Belgium
KU Leuven, ExpORL, Dept. Neurosciences, Leuven, Belgium</description>
    </item>
    
    <item>
      <title>Registration</title>
      <link>https://exporl.github.io/auditory-eeg-challenge-2024/registration/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://exporl.github.io/auditory-eeg-challenge-2024/registration/</guid>
      <description>Registration Teams can register by sending a mail to auditoryeegchallenge@kuleuven.be with the names of the team members, emails, and affiliations. Upon confirmation, teams will receive access to the training data.
Guidelines for participants Participants can submit their predictions up to five times. The latest received submission counts as the official score. The Audio-EEG challenge features two separate tasks. Participants can submit to either one track or both. Results should be accom- panied by a 2-page paper describing the proposed method The top 5 ranked teams will be invited to submit a 2-page paper, to be presented at ICASSP-2023, which should be submitted before the camera-ready deadline.</description>
    </item>
    
    <item>
      <title>Task 1: Match-mismatch</title>
      <link>https://exporl.github.io/auditory-eeg-challenge-2024/task1/description/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://exporl.github.io/auditory-eeg-challenge-2024/task1/description/</guid>
      <description>Schematic overview of the match-mismatch task Description Task 1 is a classification problem in a match-mismatch paradigm. In this paradigm, four or six inputs are presented to the model:
a segment of EEG, the time-aligned speech stimulus (matched segment) two or four imposter stimuli (mismatched segments) The task of the model is to determine which of the input stimulus segments corresponds to the EEG. The performance metric is the classification accuracy (%).</description>
    </item>
    
    <item>
      <title>Task 2: Regression</title>
      <link>https://exporl.github.io/auditory-eeg-challenge-2024/task2/description/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://exporl.github.io/auditory-eeg-challenge-2024/task2/description/</guid>
      <description>Schematic overview of the regression task Description Task 2 is a regression problem: To reconstruct the stimulus from the EEG. After reconstruction, a metric to measure the similarity is used between the reconstructed stimulus and the original stimulus. In this task, we use the Pearson correlation.
For this task, the stimulus representation is defined as the envelope, as described in the preprocessing section and as defined by the provided code.</description>
    </item>
    
    <item>
      <title>Test Set Task 1</title>
      <link>https://exporl.github.io/auditory-eeg-challenge-2024/task1/test_set/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://exporl.github.io/auditory-eeg-challenge-2024/task1/test_set/</guid>
      <description>Provided test dataset The test data for this task can be downloaded from here. The password is the same one as provided for the training set. The directory contains following items:
Preprocessed EEG test samples: The main directory contains 84 subjects&amp;rsquo; test data in the format of subject_name.json. Note that there is no test data for sub-001. Each json file contains a python dictionary with sample IDs as keys and tuples in the format of (EEG, speech1, speech2) as values.</description>
    </item>
    
    <item>
      <title>Test Set Task 2</title>
      <link>https://exporl.github.io/auditory-eeg-challenge-2024/task2/test_set/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://exporl.github.io/auditory-eeg-challenge-2024/task2/test_set/</guid>
      <description>Provided test data The test data for this task can be downloaded from here. The password is the same one as provided for the training set. The directory contains the following items:
Preprocessed EEG test samples: The main directory contains 84 subjects&amp;rsquo; test data in the format of subject_name.json. Note that there is no test data for sub-001. Each json file contains a python dictionary with samples IDs as keys and EEG segments of one minute as values.</description>
    </item>
    
  </channel>
</rss>
