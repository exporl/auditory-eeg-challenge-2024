<!DOCTYPE HTML>
<html lang="en">
    <head>

<title>General description | ICASSP 2024: Auditory EEG challenge</title>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
<link rel="stylesheet" href="/auditory-eeg-challenge-2024/style.css" />
<meta property="og:title" content="General description" />
<meta property="og:description" content="General description" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://exporl.github.io/auditory-eeg-challenge-2024/homepage_sections/general_description/" /><meta property="article:section" content="homepage_sections" />



</head>
    <body class="is-preload">
        <div id="page-wrapper"><div id="header">
    <h1><a href="https://exporl.github.io/auditory-eeg-challenge-2024/" id="logo">
        Auditory EEG Challenge - ICASSP 2024
    </a></h1>

    <nav id="nav">
        <ul>
                <li class="">
                    <a href="/auditory-eeg-challenge-2024/">Home</a>
                <li class="">
                    <a href="/auditory-eeg-challenge-2024/dataset/">Dataset</a>
                <li class="">
                    <a href="/auditory-eeg-challenge-2024/registration/">Registration</a>
                <li class="">
                    <a href="#">Task 1: Match-Mismatch</a><ul>
                        <li class="">
                            <a href="/auditory-eeg-challenge-2024/task1/description">description</a>
                        <li class="">
                            <a href="/auditory-eeg-challenge-2024/task1/test_set">test set</a>
                        <li class="">
                            <a href="/auditory-eeg-challenge-2024/task1/leaderboard">leaderboard</a>
                    </ul>
                <li class="">
                    <a href="#">Task 2: Regression</a><ul>
                        <li class="">
                            <a href="/auditory-eeg-challenge-2024/task2/description">description</a>
                        <li class="">
                            <a href="/auditory-eeg-challenge-2024/task2/test_set">test set</a>
                        <li class="">
                            <a href="/auditory-eeg-challenge-2024/task2/leaderboard">leaderboard</a>
                    </ul>
        </ul>
    </nav>
</div>

            <section class="wrapper style1">
                <div class="container">
                    

                        <div class="">
                            <div id="content">
                                <article>
    <header>
        <h2>General description</h2>
        <p>General description</p>
        
        
        <ul class="tags">
</ul>

    </header><h2 id="challenge-call">Challenge Call</h2>
<p>Various neuroimaging techniques can be used to investigate how the brain processes sound.
Electroencephalography (EEG) is popular because it is relatively easy to conduct and has a high temporal
resolution. Besides fundamental neuroscience research, EEG-based measures of auditory processing in the
brain are also helpful in detecting or diagnosing potential hearing loss. They enable differential diagnosis of
populations that can otherwise not be tested, such as young children or people with mental disabilities. In
addition, there is a growing field of research in which auditory attention is decoded from the brain, with
potential applications in smart hearing aids.
An increasingly popular method in these fields is to relate a person&rsquo;s electroencephalogram (EEG) to a
feature of the natural speech signal they were listening to. This is typically done using linear regression
to predict the EEG signal from the stimulus or to decode the stimulus from the EEG. Given the very low
signal-to-noise ratio of the EEG, this is a challenging problem, and several non-linear methods have been
proposed to improve upon the linear regression methods.
In the Auditory-EEG challenge, teams will compete to build the best model to relate speech to EEG. We
provide a large auditory EEG dataset containing data from 105 subjects who listen on average to 108 minutes
of single-speaker stimuli for a total of around 200 hours of data. We define two tasks:</p>
<p><strong>Task 1 match-mismatch</strong>: given 3 or 5 segments of speech and a segment of EEG, which segment of speech
matches the EEG?</p>
<p><strong>Task 2 regression</strong>: reconstruct the mel spectorgram from the EEG.
We provide the dataset, code for preprocessing the EEG and for creating commonly used stimulus
representations, and two baseline methods.</p>
<p>Teams can register by sending a mail to
<a href="auditoryeegchallenge@kuleuven.be">auditoryeegchallenge@kuleuven.be</a> with the names of the team members, emails, and affiliations.
The intellectual property (IP) is not transferred to the challenge organizers, i.e. if the code is shared/submitted, the participants remain
the owners of their code.</p>


                                </article>
                            </div>
                        </div>

                    
                </div>
            </section><div id="footer">
    <div class="container">
        <div class="row">
        </div>
    </div>

    <ul class="icons">
    </ul>

    <div class="copyright">
        <ul class="menu">
            
                <li>Design: <a href="https://html5up.net">HTML5 UP</a>
                <li><a href="https://github.com/half-duplex/hugo-arcana">Theme</a>
        </ul>
    </div>
</div>
</div><script src="/auditory-eeg-challenge-2024/js/jquery.min.js"></script>
<script src="/auditory-eeg-challenge-2024/js/jquery.dropotron.min.js"></script>
<script src="/auditory-eeg-challenge-2024/js/browser.min.js"></script>
<script src="/auditory-eeg-challenge-2024/js/breakpoints.min.js"></script>
<script src="/auditory-eeg-challenge-2024/js/util.js"></script>
<script src="/auditory-eeg-challenge-2024/js/main.js"></script>
</body>
</html>
