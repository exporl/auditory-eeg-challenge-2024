<!DOCTYPE HTML>
<html lang="en">
    <head>
	<meta name="generator" content="Hugo 0.103.1" />

<title>ICASSP 2024: Auditory EEG challenge</title>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
<link rel="stylesheet" href="/auditory-eeg-challenge-2024/style.css" />
<meta property="og:title" content="Home" />
<meta property="og:description" content="" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://exporl.github.io/auditory-eeg-challenge-2024/" />

</head>
    <body class="is-preload">
        <div id="page-wrapper"><div id="header">
    <h1><a href="https://exporl.github.io/auditory-eeg-challenge-2024/" id="logo">
        Auditory EEG Challenge - ICASSP 2024
    </a></h1>

    <nav id="nav">
        <ul>
                <li class="current">
                    <a href="/auditory-eeg-challenge-2024/">Home</a>
                <li class="">
                    <a href="/auditory-eeg-challenge-2024/dataset/">Dataset</a>
                <li class="">
                    <a href="/auditory-eeg-challenge-2024/registration/">Registration</a>
                <li class="">
                    <a href="#">Task 1: Match-Mismatch</a><ul>
                        <li class="">
                            <a href="/auditory-eeg-challenge-2024/task1/description">description</a>
                        <li class="">
                            <a href="/auditory-eeg-challenge-2024/task1/test_set">test_set</a>
                        <li class="">
                            <a href="/auditory-eeg-challenge-2024/task1/leaderboard">leaderboard</a>
                    </ul>
                <li class="">
                    <a href="#">Task 2: Regression</a><ul>
                        <li class="">
                            <a href="/auditory-eeg-challenge-2024/task2/description">description</a>
                        <li class="">
                            <a href="/auditory-eeg-challenge-2024/task2/test_set">test_set</a>
                        <li class="">
                            <a href="/auditory-eeg-challenge-2024/task2/leaderboard">leaderboard</a>
                    </ul>
        </ul>
    </nav>
</div><section class="wrapper style2">
    <div class="container">
        <header class="major">
            <h2>Auditory EEG decoding challenge</h2><p>This challenge focuses on establishing a relationship between measured brain activity (EEG) and an auditory stimulus</p>
        </header>
    </div>
</section>
<section class="wrapper style1">
    <div class="container">
        
            <div class=""><h2 id="test-set-update">Test set update</h2>
<p>The test set is now online.
Downloading the test set: <a href="https://homes.esat.kuleuven.be/~lbollens/sparrkulee/test_set">link</a>.
There is a separate folder for each task. For more information, look at the specific descriptions,
for either Task 1 or Task 2.</p>
<h2 id="challenge-call">Challenge Call</h2>
<p>Various neuroimaging techniques can be used to investigate how the brain processes sound.
Electroencephalography (EEG) is popular because it is relatively easy to conduct and has a high temporal
resolution. Besides fundamental neuroscience research, EEG-based measures of auditory processing in the
brain are also helpful in detecting or diagnosing potential hearing loss. They enable differential diagnosis of
populations that can otherwise not be tested, such as young children or people with mental disabilities. In
addition, there is a growing field of research in which auditory attention is decoded from the brain, with
potential applications in smart hearing aids.
An increasingly popular method in these fields is to relate a person&rsquo;s electroencephalogram (EEG) to a
feature of the natural speech signal they were listening to. This is typically done using linear regression
to predict the EEG signal from the stimulus or to decode the stimulus from the EEG. Given the very low
signal-to-noise ratio of the EEG, this is a challenging problem, and several non-linear methods have been
proposed to improve upon the linear regression methods.
In the Auditory-EEG challenge, teams will compete to build the best model to relate speech to EEG. We
provide a large auditory EEG dataset containing data from 105 subjects who listen on average to 108 minutes
of single-speaker stimuli for a total of around 200 hours of data. We define two tasks:</p>
<p><strong>Task 1 match-mismatch</strong>: given 5 segments of speech and a segment of EEG, which segment of speech
matches the EEG?</p>
<p><strong>Task 2 regression</strong>: reconstruct the mel spectorgram from the EEG.
We provide the dataset, code for preprocessing the EEG and for creating commonly used stimulus
representations, and two baseline methods.</p>
<p>Teams can register by sending a mail to
<a href="auditoryeegchallenge@kuleuven.be">auditoryeegchallenge@kuleuven.be</a> with the names of the team members, emails, and affiliations.
The intellectual property (IP) is not transferred to the challenge organizers, i.e. if the code is shared/submitted, the participants remain
the owners of their code.</p>
</div>
            <div class=""><h2 id="get-started">Get started</h2>
<ol>
<li>Send a mail to <a href="auditoryeegchallenge@kuleuven.be">auditoryeegchallenge@kuleuven.be</a> with the names of the team members, emails, and affiliations. You will receive a password to download the data</li>
<li>Download the data from <a href="https://homes.esat.kuleuven.be/~lbollens">ICASSP-2023-eeg-decoding-challenge-dataset</a>
<ul>
<li><strong>split_data(.zip)</strong> contains already preprocessed, split and normalized data; ready for model training/evaluation. If you want to get started quickly, you can opt to only download this folder/zipfile.</li>
<li><strong>preprocessed_eeg(.zip)</strong> and <strong>preprocessed_stimuli(.zip)</strong> contain preprocessed EEG and stimuli files ( speech envelope and mel spectrogram features) respectively. At this stage data is not yet split into different sets and not normalized. To go from this to the data in <strong>split_data.zip</strong>, you will have to run <em>preprocessing_code/split_and_normalize.py</em> .</li>
<li><strong>sub(_x.zip)</strong> and <strong>stimuli(.zip)</strong> contain the raw EEG and stimuli files. If you want to process the stimuli and EEG files, you can run <em>preprocessing_code/sparrKULee.py</em>. This will start from the raw files, which are stored in the BIDS-format, and perform some commonly used preprocessing steps. You are free to adapt this code to your own needs.  Speech Envelope and/or mel spectrogram features will be stored in the processed_stimuli, eeg files in the preprocessed_eeg folder.</li>
</ul>
</li>
</ol>
<p>For more details concerning the dataset, we refer to <a href="https://www.biorxiv.org/content/10.1101/2023.07.24.550310v1">the dataset paper</a>.</p>
<ol start="3">
<li>Clone the starting code from our <a href="https://github.com/exporl/auditory-eeg-challenge-2024-code">github repository</a> and get started.
The repository contains preprocessing code, as well as baseline models for each of the tasks. Do ensure that you download the 2024 version of the data and the code, as both differ slightly from the challenge from last year.</li>
</ol>
</div>
            <div class=""><p>All deadlines are at 23:59 UTC-12 (anywhere on Earth).</p>
<ul>
<li>August 30,2023 Registration opens</li>
<li>August 30, 2023: Release of training set, code, baseline methods and documentation</li>
<li><del>November 15, 2023</del> November 28, 2023: Release of evaluation test set</li>
<li><del>December 22, 2023</del> December 28, 2023: Deadline for submitting results for both tasks</li>
<li><del>January 2, 2024</del> January 9, 2024: ICASSP 2024 grand challenge 2-page paper deadline (top 5 teams only)</li>
<li><del>January 16, 2024</del> January 23, 2024: ICASSP 2024 grand challenge 2-page paper acceptance notification</li>
<li><del>January 23, 2024</del> January 30, 2024: ICASSP 2024 grand challenge 2-page camera-ready deadline</li>
<li>April 14-19, 2024: ICASSP 2024 conference</li>
<li>June 19 2024: IEEE open journal of signal processing grand challenge papers deadline</li>
</ul>
</div>
            <div class=""><h2 id="organizers">Organizers</h2>
<ul>
<li>
<p>Lies Bollens 1, 2 (<a href="mailto:lies.bollens@esat.kuleuven.be">lies.bollens@esat.kuleuven.be</a>)</p>
</li>
<li>
<p>Corentin Puffay 1, 2 (<a href="mailto:corentin.puffay@kuleuven.be">corentin.puffay@kuleuven.be</a>)</p>
</li>
<li>
<p>Bernd Accou 1, 2</p>
</li>
<li>
<p>Hugo Van hamme 1</p>
</li>
<li>
<p>Tom Francart 2</p>
</li>
</ul>
<ol>
<li>
<p>KU Leuven, PSI, Dept. of Electrical engineering (ESAT), Leuven, Belgium</p>
</li>
<li>
<p>KU Leuven, ExpORL, Dept. Neurosciences, Leuven, Belgium</p>
</li>
</ol>
</div>
    </div>
</section>
<section id="cta" class="wrapper style3">
    <div class="container">
        <header>
            <h2>Are you ready?</h2>
                <a href="task1" class="button">Get started with task 1</a>
        </header>
    </div>
</section>
<div id="footer">
    <div class="container">
        <div class="row">
        </div>
    </div>

    <ul class="icons">
    </ul>

    <div class="copyright">
        <ul class="menu">
            
                <li>Design: <a href="https://html5up.net">HTML5 UP</a>
                <li><a href="https://github.com/half-duplex/hugo-arcana">Theme</a>
        </ul>
    </div>
</div>
</div><script src="/auditory-eeg-challenge-2024/js/jquery.min.js"></script>
<script src="/auditory-eeg-challenge-2024/js/jquery.dropotron.min.js"></script>
<script src="/auditory-eeg-challenge-2024/js/browser.min.js"></script>
<script src="/auditory-eeg-challenge-2024/js/breakpoints.min.js"></script>
<script src="/auditory-eeg-challenge-2024/js/util.js"></script>
<script src="/auditory-eeg-challenge-2024/js/main.js"></script>
</body>
</html>
