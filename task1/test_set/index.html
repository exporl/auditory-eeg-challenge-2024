<!DOCTYPE HTML>
<html lang="en">
    <head>

<title>Test Set Task 1 | ICASSP 2024: Auditory EEG challenge</title>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
<link rel="stylesheet" href="/auditory-eeg-challenge-2024/style.css" />
<meta property="og:title" content="Test Set Task 1" />
<meta property="og:description" content="description of the test set for task 1" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://exporl.github.io/auditory-eeg-challenge-2024/task1/test_set/" /><meta property="article:section" content="task1" />



</head>
    <body class="is-preload">
        <div id="page-wrapper"><div id="header">
    <h1><a href="https://exporl.github.io/auditory-eeg-challenge-2024/" id="logo">
        Auditory EEG Challenge - ICASSP 2024
    </a></h1>

    <nav id="nav">
        <ul>
                <li class="">
                    <a href="/auditory-eeg-challenge-2024/">Home</a>
                <li class="">
                    <a href="/auditory-eeg-challenge-2024/dataset/">Dataset</a>
                <li class="">
                    <a href="/auditory-eeg-challenge-2024/registration/">Registration</a>
                <li class="">
                    <a href="#">Task 1: Match-Mismatch</a><ul>
                        <li class="">
                            <a href="/auditory-eeg-challenge-2024/task1/description">description</a>
                        <li class="">
                            <a href="/auditory-eeg-challenge-2024/task1/test_set">test set</a>
                        <li class="">
                            <a href="/auditory-eeg-challenge-2024/task1/leaderboard">leaderboard</a>
                    </ul>
                <li class="">
                    <a href="#">Task 2: Regression</a><ul>
                        <li class="">
                            <a href="/auditory-eeg-challenge-2024/task2/description">description</a>
                        <li class="">
                            <a href="/auditory-eeg-challenge-2024/task2/test_set">test set</a>
                        <li class="">
                            <a href="/auditory-eeg-challenge-2024/task2/leaderboard">leaderboard</a>
                    </ul>
        </ul>
    </nav>
</div>

            <section class="wrapper style1">
                <div class="container">
                    

                        <div class="">
                            <div id="content">
                                <article>
    <header>
        <h2>Test Set Task 1</h2>
        <p>description of the test set for task 1</p>
        
        
        <ul class="tags">
</ul>

    </header><hr>
<h3 id="provided-test-dataset">Provided test dataset</h3>
<p>The test data for this task can be downloaded from <a href="https://kuleuven-my.sharepoint.com/:f:/g/personal/lies_bollens_kuleuven_be/EoOWlx13No1Jnlo4tV5q3_4BuDN51NYAOpIlHQ44MVGh4Q?e=cLi33z">here</a>.
The password is the same one as provided for the training set.
The directory contains following items:</p>
<ol>
<li>
<p><strong>Preprocessed EEG test samples</strong>: The main directory contains 84 subjects&rsquo; test data in the format
of subject_name.json. Note that there is no test data for sub-001. Each json file contains a python dictionary with
sample IDs as keys and tuples in the format of (EEG, speech1, speech2) as values. First element of the tuple is preprocessed
EEG of 3 seconds long with fs=64 Hz. speech1 and speech2 are pointers to the actual speech segments which are located
in the envelope_segments and/or stimuli_segments. You need to probably convert EEG from list to numpy array.</p>
</li>
<li>
<p><strong>envelope_segments</strong>: This directory contains envelope of speech segments used in the test samples. You can already use this
directory if you trained your model with envelope as speech feature. You can get the Envelope by using the following code:</p>
<p><em>import numpy as np</em></p>
<p><em>data = np.load(speech_seg.npz)</em></p>
<p><em>speech, fs = data[&rsquo;envelope&rsquo;], data[&lsquo;fs&rsquo;]</em></p>
</li>
<li>
<p><strong>raw_eeg</strong>: We also provide the corresponding raw EEG files for each subject. If you prefer to have access
to the raw EEG and do your own preprocessing, then you can use this directory. The json files in this directory have exactly
the same format as of the preprocessed EEG files. Sampling rate of the raw EEG is 1024 Hz.</p>
</li>
<li>
<p><strong>stimuli_segments</strong>: This directory contains raw speech segments at 48 kHz. You can load the raw stimulus segments
using the following code:</p>
</li>
</ol>
<p><em>data = np.load(speech_seg.npz)</em></p>
<p><em>speech, fs = data[&lsquo;audio&rsquo;], data[&lsquo;fs&rsquo;]</em></p>
<h3 id="expected-output">Expected output</h3>
<p>As an output, participants should upload a zip file, containing json files to <a href="https://kuleuven-my.sharepoint.com/:f:/g/personal/lies_bollens_kuleuven_be/EqTaLSL7EQ5EtDgSf-W844QBKuAbvuJoagzaVBZEtDx7Dw">the following link</a>
The files should follow the following naming convention:</p>
<p>task_1_group_<strong>group_name</strong>_submission _<strong>submission_number</strong>.zip</p>
<p>where <strong>submission_number</strong> should be 1 for
the first submission and can go up to 5. We will use the latest submission as the final submission, from which the ranking will be calculated. Groups that have not yet supplied their group name, should send a mail to the
organisers where they specify their name. When uploading, you will be prompted to enter a name. Please enter the name of one of the officially registered participants.</p>
<p>The json file(s) should contain the predicted labels for all EEG segments. Each entry in the submitted file should be of the form <strong>(EEG ID) : (label)</strong>.
The label is 0 if stimulus 1 matches EEG and 1 if stimulus 2 matches EEG. In case of absent EEG
ID entries, the sample will be assigned the wrong label. Labels should be either 0 or 1.</p>
<p>We provide the script <a href="https://github.com/exporl/auditory-eeg-challenge-2023-code/blob/main/task1_match_mismatch/experiments/predict_test.py">predict_test.py</a>, which loads a pretrained model, loops over all the data of the test set, predicts the output labels and returns json files
in the correct format.</p>
<p>For evaluation, we will calculate the mean accuracy score per subject. Then, we will calculate the mean over all the subjects means for both
test set 1 and test set 2 and add them to obtain a final <strong>score</strong>, which will be updated in the online leaderboard.</p>


                                </article>
                            </div>
                        </div>

                    
                </div>
            </section><div id="footer">
    <div class="container">
        <div class="row">
        </div>
    </div>

    <ul class="icons">
    </ul>

    <div class="copyright">
        <ul class="menu">
            
                <li>Design: <a href="https://html5up.net">HTML5 UP</a>
                <li><a href="https://github.com/half-duplex/hugo-arcana">Theme</a>
        </ul>
    </div>
</div>
</div><script src="/auditory-eeg-challenge-2024/js/jquery.min.js"></script>
<script src="/auditory-eeg-challenge-2024/js/jquery.dropotron.min.js"></script>
<script src="/auditory-eeg-challenge-2024/js/browser.min.js"></script>
<script src="/auditory-eeg-challenge-2024/js/breakpoints.min.js"></script>
<script src="/auditory-eeg-challenge-2024/js/util.js"></script>
<script src="/auditory-eeg-challenge-2024/js/main.js"></script>
</body>
</html>
